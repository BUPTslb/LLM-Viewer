{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636e9391",
   "metadata": {},
   "source": [
    "# 测试hot参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a518ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "模型加载成功！\n",
      "警告: 数据集只有 61 个有效样本\n",
      "使用 61 个样本进行批量分析\n",
      "模型总层数: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理样本: 100%|██████████| 61/61 [00:01<00:00, 56.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "整体平均激活密度 (基于 61 个样本): 99.82% (越低表示越稀疏)\n",
      "层 0: 总神经元 1536, 热神经元 574 (37.37%), 冷神经元 962 (62.63%)\n",
      "层 1: 总神经元 1536, 热神经元 290 (18.88%), 冷神经元 1246 (81.12%)\n",
      "层 2: 总神经元 1536, 热神经元 143 (9.31%), 冷神经元 1393 (90.69%)\n",
      "层 3: 总神经元 1536, 热神经元 452 (29.43%), 冷神经元 1084 (70.57%)\n",
      "层 4: 总神经元 1536, 热神经元 428 (27.86%), 冷神经元 1108 (72.14%)\n",
      "层 5: 总神经元 1536, 热神经元 475 (30.92%), 冷神经元 1061 (69.08%)\n",
      "层 6: 总神经元 1536, 热神经元 618 (40.23%), 冷神经元 918 (59.77%)\n",
      "层 7: 总神经元 1536, 热神经元 624 (40.62%), 冷神经元 912 (59.38%)\n",
      "层 8: 总神经元 1536, 热神经元 641 (41.73%), 冷神经元 895 (58.27%)\n",
      "层 9: 总神经元 1536, 热神经元 585 (38.09%), 冷神经元 951 (61.91%)\n",
      "层 10: 总神经元 1536, 热神经元 581 (37.83%), 冷神经元 955 (62.17%)\n",
      "层 11: 总神经元 1536, 热神经元 596 (38.80%), 冷神经元 940 (61.20%)\n",
      "层 12: 总神经元 1536, 热神经元 627 (40.82%), 冷神经元 909 (59.18%)\n",
      "层 13: 总神经元 1536, 热神经元 602 (39.19%), 冷神经元 934 (60.81%)\n",
      "层 14: 总神经元 1536, 热神经元 581 (37.83%), 冷神经元 955 (62.17%)\n",
      "层 15: 总神经元 1536, 热神经元 531 (34.57%), 冷神经元 1005 (65.43%)\n",
      "层 16: 总神经元 1536, 热神经元 584 (38.02%), 冷神经元 952 (61.98%)\n",
      "层 17: 总神经元 1536, 热神经元 623 (40.56%), 冷神经元 913 (59.44%)\n",
      "层 18: 总神经元 1536, 热神经元 587 (38.22%), 冷神经元 949 (61.78%)\n",
      "层 19: 总神经元 1536, 热神经元 566 (36.85%), 冷神经元 970 (63.15%)\n",
      "层 20: 总神经元 1536, 热神经元 569 (37.04%), 冷神经元 967 (62.96%)\n",
      "层 21: 总神经元 1536, 热神经元 544 (35.42%), 冷神经元 992 (64.58%)\n",
      "层 22: 总神经元 1536, 热神经元 521 (33.92%), 冷神经元 1015 (66.08%)\n",
      "层 23: 总神经元 1536, 热神经元 557 (36.26%), 冷神经元 979 (63.74%)\n",
      "层 24: 总神经元 1536, 热神经元 566 (36.85%), 冷神经元 970 (63.15%)\n",
      "层 25: 总神经元 1536, 热神经元 507 (33.01%), 冷神经元 1029 (66.99%)\n",
      "层 26: 总神经元 1536, 热神经元 160 (10.42%), 冷神经元 1376 (89.58%)\n",
      "层 27: 总神经元 1536, 热神经元 348 (22.66%), 冷神经元 1188 (77.34%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm  # 进度条\n",
    "\n",
    "# 配置\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "num_samples = 100  # 批量样本数量，可调整\n",
    "max_length = 128   # 最大序列长度，控制内存\n",
    "dataset_name = \"wikitext\"  # 数据集名称，可换成其他如\"gsm8k\"\n",
    "split = \"test\"  # 数据集拆分\n",
    "\n",
    "# 加载模型和tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "    print(\"模型加载成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"加载模型失败：{e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 加载数据集（取前num_samples个样本）\n",
    "dataset = load_dataset(dataset_name, \"wikitext-2-raw-v1\", split=split)  # 示例数据集\n",
    "# 修改：直接访问'text'列的切片，返回字符串列表\n",
    "text_list = dataset['text'][:num_samples]  # 获取前num_samples个文本字符串\n",
    "samples = [text[:max_length] for text in text_list if text.strip()]  # 截断、过滤空行\n",
    "if len(samples) < num_samples:\n",
    "    print(f\"警告: 数据集只有 {len(samples)} 个有效样本\")\n",
    "print(f\"使用 {len(samples)} 个样本进行批量分析\")\n",
    "\n",
    "# 获取层数（Qwen的Transformer层）\n",
    "num_layers = len(model.model.layers)\n",
    "print(f\"模型总层数: {num_layers}\")\n",
    "\n",
    "# 定义钩子函数（为每个层准备一个激活列表）\n",
    "activations_per_layer = [[] for _ in range(num_layers)]  # 每个层一个列表，存储所有样本的激活\n",
    "\n",
    "def hook_fn(layer_idx):\n",
    "    def fn(module, input, output):\n",
    "        if isinstance(output, tuple):\n",
    "            activations_per_layer[layer_idx].append(output[0].detach().cpu())  # 移到CPU节省GPU内存\n",
    "        else:\n",
    "            activations_per_layer[layer_idx].append(output.detach().cpu())\n",
    "    return fn\n",
    "\n",
    "# 为所有层的mlp注册钩子\n",
    "handles = []\n",
    "for i in range(num_layers):\n",
    "    hook = model.model.layers[i].mlp.register_forward_hook(hook_fn(i))\n",
    "    handles.append(hook)\n",
    "\n",
    "# 批量运行推理\n",
    "with torch.no_grad():\n",
    "    for text in tqdm(samples, desc=\"处理样本\"):\n",
    "        if not text.strip():  # 跳过空文本\n",
    "            continue\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True).to(device)\n",
    "        _ = model(**inputs)  # 运行推理，钩子会自动捕获\n",
    "\n",
    "# 移除所有钩子\n",
    "for handle in handles:\n",
    "    handle.remove()\n",
    "\n",
    "# 分析激活\n",
    "if not any(activations_per_layer):  # 检查是否捕获到数据\n",
    "    print(\"未捕获到激活值，请检查钩子注册或输入。\")\n",
    "else:\n",
    "    # 计算整体平均激活密度（避免cat变长张量：分别计算每个激活的密度，然后平均）\n",
    "    densities = []\n",
    "    for layer_acts in activations_per_layer:\n",
    "        for act in layer_acts:\n",
    "            if act.numel() > 0:  # 跳过空张量\n",
    "                density = (act.abs() > 1e-3).float().mean().item()\n",
    "                densities.append(density)\n",
    "    if densities:\n",
    "        avg_density = sum(densities) / len(densities)\n",
    "        print(f\"\\n整体平均激活密度 (基于 {len(samples)} 个样本): {avg_density * 100:.2f}% (越低表示越稀疏)\")\n",
    "    else:\n",
    "        print(\"无有效激活数据，无法计算密度\")\n",
    "\n",
    "    # 为每个层计算冷热神经元百分比（处理变长seq_len：先沿seq_len平均，再聚合）\n",
    "    for layer_idx in range(num_layers):\n",
    "        layer_acts = activations_per_layer[layer_idx]\n",
    "        if not layer_acts:  \n",
    "            print(f\"层 {layer_idx}: 无激活数据\")\n",
    "            continue\n",
    "        # 对每个样本的激活沿seq_len维度平均，得到[1, hidden_size]列表\n",
    "        per_sample_means = [act.mean(dim=1) for act in layer_acts if act.numel() > 0]  # [1, hidden_size] per sample\n",
    "        if not per_sample_means:\n",
    "            print(f\"层 {layer_idx}: 无有效激活数据\")\n",
    "            continue\n",
    "        # cat成 [num_valid_samples, hidden_size]，然后沿样本维度平均\n",
    "        aggregated_act = torch.cat(per_sample_means, dim=0).abs().mean(dim=0)  # [hidden_size]\n",
    "        avg_activation = aggregated_act.mean().item()\n",
    "        total_neurons = aggregated_act.size(0)\n",
    "        hot_neurons = (aggregated_act > avg_activation).sum().item()\n",
    "        hot_pct = (hot_neurons / total_neurons * 100) if total_neurons > 0 else 0\n",
    "        cold_pct = 100 - hot_pct\n",
    "        print(f\"层 {layer_idx}: 总神经元 {total_neurons}, 热神经元 {hot_neurons} ({hot_pct:.2f}%), 冷神经元 {total_neurons - hot_neurons} ({cold_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fa2f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "加载模型失败：You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/google/gemma-2-2b-it.\n",
      "403 Client Error. (Request ID: Root=1-688074f7-7a26949d638d875d64a7133e;ed9af414-1386-43f9-89b7-8af070807d52)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-2-2b-it/resolve/main/config.json.\n",
      "Access to model google/gemma-2-2b-it is restricted and you are not in the authorized list. Visit https://huggingface.co/google/gemma-2-2b-it to ask for access.\n",
      "模型总层数: 24\n",
      "\n",
      "=== 处理数据集: wikitext (split: test) ===\n",
      "警告: 数据集只有 321 个有效样本\n",
      "使用 321 个样本进行分析\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理样本: 100%|██████████| 321/321 [00:06<00:00, 47.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果保存为: google_gemma_2_2b_it/wikitext_activation_results.json\n",
      "\n",
      "=== 处理数据集: gsm8k (split: train) ===\n",
      "使用 500 个样本进行分析\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理样本: 100%|██████████| 500/500 [00:11<00:00, 43.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果保存为: google_gemma_2_2b_it/gsm8k_activation_results.json\n",
      "\n",
      "=== 处理数据集: cc_news (split: train) ===\n",
      "使用 500 个样本进行分析\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理样本: 100%|██████████| 500/500 [00:10<00:00, 45.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果保存为: google_gemma_2_2b_it/cc_news_activation_results.json\n",
      "\n",
      "=== 处理数据集: squad (split: train) ===\n",
      "使用 500 个样本进行分析\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理样本: 100%|██████████| 500/500 [00:08<00:00, 59.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果保存为: google_gemma_2_2b_it/squad_activation_results.json\n",
      "\n",
      "=== 处理数据集: cnn_dailymail (split: train) ===\n",
      "使用 500 个样本进行分析\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理样本: 100%|██████████| 500/500 [00:07<00:00, 67.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果保存为: google_gemma_2_2b_it/cnn_dailymail_activation_results.json\n",
      "\n",
      "所有数据集处理完成！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm  # 进度条\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 可选：启用expandable_segments以避免内存碎片（如果需要）\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# 配置\n",
    "# model_name =    \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# model_name =    \"meta-llama/Llama-3.2-1B-Instruct\" # Llama3.2-1B (Instruct版本)\n",
    "# model_name =    \"Qwen/Qwen1.5-1.8B-Chat\"          # Qwen1.5-1.8B (Chat版本)\n",
    "model_name =    \"google/gemma-2-2b-it\"             # Gemma2-2B (Instruct版本)\n",
    "# model_name =    \"microsoft/phi-2\"                  # Phi-2-2.7B (基础版本，无Instruct)\n",
    "# model_name =    \"microsoft/Phi-3.5-mini-instruct\"  # Phi-3.5-Mini-Instruct (3.8B Mini版本)\n",
    "# model_name =    \"Qwen/Qwen1.5-4B-Chat\"            # Qwen1.5 4B (Chat版本)\n",
    "# model_name =    \"THUDM/chatglm2-6b\"                # ChatGLM2 6B\n",
    "# model_name =    \"facebook/opt-6.7b\"                # OPT6.7B (基础版本)\n",
    "# model_name =    \"mistralai/Mistral-7B-Instruct-v0.1\" # Mistral-7B (Instruct版本)\n",
    "# model_name =    \"Qwen/Qwen2-7B-Instruct\"          # Qwen2-7B (Instruct版本)\n",
    "# model_name =    \"meta-llama/Meta-Llama-3-8B-Instruct\" # LLaMA3-8B (Instruct版本)\n",
    "num_samples = 500  # 每个数据集的样本数量，可调整为1000+\n",
    "max_length = 128   # 最大序列长度，控制内存\n",
    "\n",
    "# 数据集列表：(dataset_name, config, split, text_column)\n",
    "# text_column 是提取文本的键；如果需要组合多个列，在代码中处理\n",
    "# 更新：gsm8k的config从None改为\"main\"\n",
    "datasets_to_use = [\n",
    "    (\"wikitext\", \"wikitext-2-raw-v1\", \"test\", \"text\"),  # 文本数据集\n",
    "    (\"gsm8k\", \"main\", \"train\", \"question\"),  # 数学问题（使用'main'配置）\n",
    "    (\"cc_news\", None, \"train\", \"text\"),  # 新闻文本（bookcorpus的替代）\n",
    "    (\"squad\", None, \"train\", \"question\"),  # 问答（将组合question + context）\n",
    "    (\"cnn_dailymail\", \"3.0.0\", \"train\", \"article\")  # 新闻文章\n",
    "]\n",
    "\n",
    "# 加载模型和tokenizer（只加载一次）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "    print(\"模型加载成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"加载模型失败：{e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 获取层数（Qwen的Transformer层）\n",
    "num_layers = len(model.model.layers)\n",
    "print(f\"模型总层数: {num_layers}\")\n",
    "\n",
    "# 为所有层的mlp注册钩子（只注册一次）\n",
    "activations_per_layer = None  # 将在循环中重置\n",
    "handles = []\n",
    "def hook_fn(layer_idx):\n",
    "    def fn(module, input, output):\n",
    "        if isinstance(output, tuple):\n",
    "            activations_per_layer[layer_idx].append(output[0].detach().cpu())\n",
    "        else:\n",
    "            activations_per_layer[layer_idx].append(output.detach().cpu())\n",
    "    return fn\n",
    "for i in range(num_layers):\n",
    "    hook = model.model.layers[i].mlp.register_forward_hook(hook_fn(i))\n",
    "    handles.append(hook)\n",
    "\n",
    "# 循环每个数据集\n",
    "for ds_name, ds_config, ds_split, text_column in datasets_to_use:\n",
    "    print(f\"\\n=== 处理数据集: {ds_name} (split: {ds_split}) ===\")\n",
    "    try:\n",
    "        # 加载数据集\n",
    "        if ds_config:\n",
    "            dataset = load_dataset(ds_name, ds_config, split=ds_split)\n",
    "        else:\n",
    "            dataset = load_dataset(ds_name, split=ds_split)\n",
    "        \n",
    "        # 提取前num_samples个样本的文本\n",
    "        text_list = dataset[text_column][:num_samples]  # 获取文本列表\n",
    "        \n",
    "        # 特殊处理：如果数据集需要组合多个列（如squad）\n",
    "        if ds_name == \"squad\":\n",
    "            context_list = dataset['context'][:num_samples]\n",
    "            text_list = [q + \" \" + c for q, c in zip(text_list, context_list)]  # 组合question + context\n",
    "        \n",
    "        samples = [text[:max_length] for text in text_list if isinstance(text, str) and text.strip()]  # 截断、过滤无效\n",
    "        if len(samples) < num_samples:\n",
    "            print(f\"警告: 数据集只有 {len(samples)} 个有效样本\")\n",
    "        if len(samples) == 0:\n",
    "            print(\"跳过: 无有效样本\")\n",
    "            continue\n",
    "        print(f\"使用 {len(samples)} 个样本进行分析\")\n",
    "        \n",
    "        # 重置激活列表\n",
    "        activations_per_layer = [[] for _ in range(num_layers)]\n",
    "        \n",
    "        # 批量运行推理\n",
    "        with torch.no_grad():\n",
    "            for text in tqdm(samples, desc=\"处理样本\"):\n",
    "                if not text.strip():\n",
    "                    continue\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True).to(device)\n",
    "                _ = model(**inputs)  # 运行推理，钩子捕获\n",
    "        \n",
    "        # 分析激活（与之前相同，处理变长序列）\n",
    "        if not any(activations_per_layer):\n",
    "            print(\"未捕获到激活值，跳过分析\")\n",
    "            continue\n",
    "        \n",
    "        # 计算整体平均激活密度\n",
    "        densities = []\n",
    "        for layer_acts in activations_per_layer:\n",
    "            for act in layer_acts:\n",
    "                if act.numel() > 0:\n",
    "                    density = (act.abs() > 1e-3).float().mean().item()\n",
    "                    densities.append(density)\n",
    "        if densities:\n",
    "            avg_density = sum(densities) / len(densities)\n",
    "        else:\n",
    "            avg_density = 0.0\n",
    "            print(\"无有效激活数据，无法计算密度\")\n",
    "        \n",
    "        # 为每个层计算冷热神经元百分比，并收集数据\n",
    "        layers_data = []\n",
    "        for layer_idx in range(num_layers):\n",
    "            layer_acts = activations_per_layer[layer_idx]\n",
    "            if not layer_acts:\n",
    "                continue\n",
    "            per_sample_means = [act.mean(dim=1) for act in layer_acts if act.numel() > 0]\n",
    "            if not per_sample_means:\n",
    "                continue\n",
    "            aggregated_act = torch.cat(per_sample_means, dim=0).abs().mean(dim=0)  # [hidden_size]\n",
    "            avg_activation = aggregated_act.mean().item()\n",
    "            total_neurons = aggregated_act.size(0)\n",
    "            hot_neurons = (aggregated_act > avg_activation).sum().item()\n",
    "            hot_pct = (hot_neurons / total_neurons * 100) if total_neurons > 0 else 0\n",
    "            cold_pct = 100 - hot_pct\n",
    "            layers_data.append({\n",
    "                \"layer_id\": layer_idx,\n",
    "                \"total_neurons\": total_neurons,\n",
    "                \"hot_neurons\": hot_neurons,\n",
    "                \"hot_pct\": hot_pct,\n",
    "                \"cold_neurons\": total_neurons - hot_neurons,\n",
    "                \"cold_pct\": cold_pct\n",
    "            })\n",
    "        \n",
    "        # 保存为JSON：创建模型名称的文件夹（清理斜杠为下划线）\n",
    "        model_folder = model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")  # 清理为有效文件夹名，例如 \"meta_llama_Llama_3_2_1B_Instruct\"\n",
    "        os.makedirs(model_folder, exist_ok=True)  # 创建文件夹，如果不存在\n",
    "        json_filename = f\"{ds_name}_activation_results.json\"\n",
    "        json_path = os.path.join(model_folder, json_filename)  # 完整路径\n",
    "        results = {\n",
    "            \"dataset\": ds_name,\n",
    "            \"split\": ds_split,\n",
    "            \"num_samples\": len(samples),\n",
    "            \"average_density\": avg_density,\n",
    "            \"layers\": layers_data\n",
    "        }\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        print(f\"结果保存为: {json_path}\")\n",
    "        \n",
    "        # 清空GPU缓存，准备下一个数据集\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"处理 {ds_name} 失败: {e}\")\n",
    "\n",
    "# 移除钩子（在所有数据集后）\n",
    "for handle in handles:\n",
    "    handle.remove()\n",
    "print(\"\\n所有数据集处理完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d9215",
   "metadata": {},
   "source": [
    "## 根据模型结构灵活调整，检测激活稀疏性质"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5c5ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shen/miniconda3/envs/sglang/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]\n",
      "处理样本:   0%|          | 0/321 [00:00<?, ?it/s]The 'batch_size' argument of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'max_batch_size' argument instead.\n",
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n",
      "处理样本: 100%|██████████| 321/321 [00:16<00:00, 19.57it/s]\n",
      "处理样本: 100%|██████████| 500/500 [00:20<00:00, 24.51it/s]\n",
      "处理样本: 100%|██████████| 500/500 [00:25<00:00, 19.65it/s]\n",
      "处理样本: 100%|██████████| 500/500 [00:14<00:00, 33.55it/s]\n",
      "处理样本: 100%|██████████| 500/500 [00:21<00:00, 22.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 可选：启用expandable_segments以避免内存碎片\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "class ModelArchitectureAdapter:\n",
    "    \"\"\"适配不同模型架构的辅助类\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_model_layers(model, model_name):\n",
    "        \"\"\"根据模型类型获取transformer层\"\"\"\n",
    "        model_name_lower = model_name.lower()\n",
    "        \n",
    "        # ChatGLM系列\n",
    "        if \"chatglm\" in model_name_lower:\n",
    "            if hasattr(model, 'transformer') and hasattr(model.transformer, 'encoder'):\n",
    "                return model.transformer.encoder.layers\n",
    "            elif hasattr(model, 'transformer') and hasattr(model.transformer, 'layers'):\n",
    "                return model.transformer.layers\n",
    "        \n",
    "        # OPT系列\n",
    "        elif \"opt\" in model_name_lower:\n",
    "            return model.model.decoder.layers\n",
    "        \n",
    "        # Phi系列\n",
    "        elif \"phi\" in model_name_lower:\n",
    "            if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "                return model.model.layers\n",
    "            elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "                return model.transformer.h\n",
    "        \n",
    "        # Gemma系列\n",
    "        elif \"gemma\" in model_name_lower:\n",
    "            if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "                return model.model.layers\n",
    "        \n",
    "        # LLaMA, Mistral, Qwen等标准架构\n",
    "        elif hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "            return model.model.layers\n",
    "        \n",
    "        # 备用：直接访问layers\n",
    "        elif hasattr(model, 'layers'):\n",
    "            return model.layers\n",
    "        \n",
    "        # 备用：transformer.layers\n",
    "        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'layers'):\n",
    "            return model.transformer.layers\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"无法识别模型 {model_name} 的层结构\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mlp_modules(layer, model_name):\n",
    "        \"\"\"根据模型类型获取MLP模块，返回需要监控的模块列表\"\"\"\n",
    "        modules_to_monitor = []\n",
    "        model_name_lower = model_name.lower()\n",
    "        \n",
    "        # 标准MLP结构\n",
    "        if hasattr(layer, 'mlp'):\n",
    "            modules_to_monitor.append(('mlp', layer.mlp))\n",
    "        \n",
    "        # ChatGLM的FFN结构\n",
    "        elif hasattr(layer, 'mlp') and hasattr(layer.mlp, 'dense_h_to_4h'):\n",
    "            modules_to_monitor.append(('mlp.dense_h_to_4h', layer.mlp.dense_h_to_4h))\n",
    "        \n",
    "        # 一些模型使用feed_forward\n",
    "        elif hasattr(layer, 'feed_forward'):\n",
    "            modules_to_monitor.append(('feed_forward', layer.feed_forward))\n",
    "        \n",
    "        # Phi模型可能使用不同的名称\n",
    "        elif hasattr(layer, 'fc1') and hasattr(layer, 'fc2'):\n",
    "            modules_to_monitor.append(('fc1', layer.fc1))\n",
    "        \n",
    "        # 如果都没有，尝试获取所有包含fc或mlp的子模块\n",
    "        else:\n",
    "            for name, module in layer.named_modules():\n",
    "                if any(key in name.lower() for key in ['mlp', 'fc', 'ffn', 'feed_forward']):\n",
    "                    if hasattr(module, 'forward') and len(list(module.parameters())) > 0:\n",
    "                        modules_to_monitor.append((name, module))\n",
    "                        break\n",
    "        \n",
    "        if not modules_to_monitor:\n",
    "            logger.warning(f\"模型 {model_name} 的层中未找到MLP模块，尝试监控整个层\")\n",
    "            modules_to_monitor.append(('layer', layer))\n",
    "        \n",
    "        return modules_to_monitor\n",
    "\n",
    "class SparsityDetector:\n",
    "    def __init__(self, model_name, device='cuda', use_single_gpu=True):\n",
    "        self.model_name = model_name\n",
    "        self.use_single_gpu = use_single_gpu\n",
    "        \n",
    "        # 设置设备\n",
    "        if use_single_gpu and torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "            self.device_map = None\n",
    "        elif torch.cuda.is_available():\n",
    "            self.device = None\n",
    "            self.device_map = 'auto'\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            self.device_map = None\n",
    "            \n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.layers = None\n",
    "        self.handles = []\n",
    "        self.activations_per_layer = None\n",
    "        \n",
    "        logger.info(f\"使用设备: {self.device if self.device else 'auto (multi-GPU)'}\")\n",
    "        self._load_model()\n",
    "        self._setup_hooks()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"加载模型和tokenizer\"\"\"\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            # 设置pad_token（如果没有）\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "            # 加载模型\n",
    "            if self.use_single_gpu and self.device.type == 'cuda':\n",
    "                # 单GPU模式：加载到单个GPU\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    low_cpu_mem_usage=True\n",
    "                ).to(self.device)\n",
    "            elif self.device_map == 'auto':\n",
    "                # 多GPU模式\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    device_map=self.device_map,\n",
    "                    low_cpu_mem_usage=True\n",
    "                )\n",
    "            else:\n",
    "                # CPU模式\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    torch_dtype=torch.float32,\n",
    "                    low_cpu_mem_usage=True\n",
    "                ).to(self.device)\n",
    "            \n",
    "            self.model.eval()\n",
    "            logger.info(f\"模型 {self.model_name} 加载成功！\")\n",
    "            \n",
    "            # 获取模型层\n",
    "            self.layers = ModelArchitectureAdapter.get_model_layers(self.model, self.model_name)\n",
    "            logger.info(f\"模型总层数: {len(self.layers)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"加载模型失败：{e}\")\n",
    "            raise\n",
    "    \n",
    "    def _setup_hooks(self):\n",
    "        \"\"\"设置前向钩子\"\"\"\n",
    "        self.activations_per_layer = [[] for _ in range(len(self.layers))]\n",
    "        \n",
    "        def create_hook(layer_idx):\n",
    "            def hook_fn(module, input, output):\n",
    "                # 处理不同类型的输出\n",
    "                if isinstance(output, tuple):\n",
    "                    act = output[0]\n",
    "                elif isinstance(output, dict):\n",
    "                    act = output.get('hidden_states', output.get('last_hidden_state', None))\n",
    "                    if act is None:\n",
    "                        act = list(output.values())[0]\n",
    "                else:\n",
    "                    act = output\n",
    "                \n",
    "                if act is not None and isinstance(act, torch.Tensor):\n",
    "                    # 确保激活值在CPU上以节省GPU内存\n",
    "                    self.activations_per_layer[layer_idx].append(act.detach().cpu())\n",
    "            return hook_fn\n",
    "        \n",
    "        # 为每层注册钩子\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            mlp_modules = ModelArchitectureAdapter.get_mlp_modules(layer, self.model_name)\n",
    "            for module_name, module in mlp_modules:\n",
    "                hook = module.register_forward_hook(create_hook(i))\n",
    "                self.handles.append(hook)\n",
    "                logger.debug(f\"Layer {i}: 在 {module_name} 上注册了钩子\")\n",
    "    \n",
    "    def process_dataset(self, dataset_info, num_samples=500, max_length=128, batch_size=1):\n",
    "        \"\"\"处理单个数据集\"\"\"\n",
    "        ds_name, ds_config, ds_split, text_column = dataset_info\n",
    "        logger.info(f\"\\n=== 处理数据集: {ds_name} (split: {ds_split}) ===\")\n",
    "        \n",
    "        try:\n",
    "            # 加载数据集\n",
    "            if ds_config:\n",
    "                dataset = load_dataset(ds_name, ds_config, split=ds_split, streaming=False)\n",
    "            else:\n",
    "                dataset = load_dataset(ds_name, split=ds_split, streaming=False)\n",
    "            \n",
    "            # 提取文本\n",
    "            texts = self._extract_texts(dataset, ds_name, text_column, num_samples)\n",
    "            \n",
    "            if not texts:\n",
    "                logger.warning(\"无有效样本，跳过\")\n",
    "                return None\n",
    "            \n",
    "            logger.info(f\"使用 {len(texts)} 个样本进行分析\")\n",
    "            \n",
    "            # 重置激活值\n",
    "            self.activations_per_layer = [[] for _ in range(len(self.layers))]\n",
    "            \n",
    "            # 批量推理\n",
    "            self._run_inference(texts, max_length, batch_size)\n",
    "            \n",
    "            # 分析结果\n",
    "            results = self._analyze_activations(ds_name, ds_split, len(texts))\n",
    "            \n",
    "            # 清空GPU缓存\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"处理 {ds_name} 失败: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def _extract_texts(self, dataset, ds_name, text_column, num_samples):\n",
    "        \"\"\"从数据集提取文本\"\"\"\n",
    "        # 获取数据\n",
    "        total_samples = len(dataset)\n",
    "        actual_samples = min(num_samples, total_samples)\n",
    "        \n",
    "        if ds_name == \"squad\":\n",
    "            # 特殊处理：组合question和context\n",
    "            texts = []\n",
    "            for i in range(actual_samples):\n",
    "                q = dataset[i]['question']\n",
    "                c = dataset[i]['context']\n",
    "                texts.append(f\"{q} {c}\")\n",
    "        else:\n",
    "            # 通用处理\n",
    "            texts = []\n",
    "            for i in range(actual_samples):\n",
    "                text = dataset[i][text_column]\n",
    "                if isinstance(text, str) and text.strip():\n",
    "                    texts.append(text)\n",
    "        \n",
    "        return texts[:num_samples]\n",
    "    \n",
    "    def _run_inference(self, texts, max_length, batch_size=1):\n",
    "        \"\"\"运行推理并收集激活值\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, len(texts), batch_size), desc=\"处理样本\"):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                \n",
    "                try:\n",
    "                    # 准备输入\n",
    "                    inputs = self.tokenizer(\n",
    "                        batch_texts, \n",
    "                        return_tensors=\"pt\", \n",
    "                        max_length=max_length, \n",
    "                        truncation=True,\n",
    "                        padding=True\n",
    "                    )\n",
    "                    \n",
    "                    # 将输入移动到正确的设备\n",
    "                    if self.device:\n",
    "                        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                    elif hasattr(self.model, 'device'):\n",
    "                        # 多GPU情况下，使用模型的第一个设备\n",
    "                        first_device = next(self.model.parameters()).device\n",
    "                        inputs = {k: v.to(first_device) for k, v in inputs.items()}\n",
    "                    \n",
    "                    # 推理\n",
    "                    _ = self.model(**inputs)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"处理批次失败: {e}\")\n",
    "                    # 尝试逐个处理该批次中的样本\n",
    "                    for text in batch_texts:\n",
    "                        try:\n",
    "                            inputs = self.tokenizer(\n",
    "                                text, \n",
    "                                return_tensors=\"pt\", \n",
    "                                max_length=max_length, \n",
    "                                truncation=True,\n",
    "                                padding=True\n",
    "                            )\n",
    "                            \n",
    "                            if self.device:\n",
    "                                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                            elif hasattr(self.model, 'device'):\n",
    "                                first_device = next(self.model.parameters()).device\n",
    "                                inputs = {k: v.to(first_device) for k, v in inputs.items()}\n",
    "                            \n",
    "                            _ = self.model(**inputs)\n",
    "                        except Exception as e2:\n",
    "                            logger.warning(f\"处理单个样本失败: {e2}\")\n",
    "                            continue\n",
    "    \n",
    "    def _analyze_activations(self, ds_name, ds_split, num_samples):\n",
    "        \"\"\"分析激活值的稀疏性\"\"\"\n",
    "        if not any(self.activations_per_layer):\n",
    "            logger.warning(\"未捕获到激活值\")\n",
    "            return None\n",
    "        \n",
    "        # 计算整体平均激活密度\n",
    "        densities = []\n",
    "        for layer_acts in self.activations_per_layer:\n",
    "            for act in layer_acts:\n",
    "                if act.numel() > 0:\n",
    "                    density = (act.abs() > 1e-3).float().mean().item()\n",
    "                    densities.append(density)\n",
    "        \n",
    "        avg_density = sum(densities) / len(densities) if densities else 0.0\n",
    "        \n",
    "        # 分析每层的冷热神经元\n",
    "        layers_data = []\n",
    "        for layer_idx in range(len(self.layers)):\n",
    "            layer_acts = self.activations_per_layer[layer_idx]\n",
    "            if not layer_acts:\n",
    "                continue\n",
    "            \n",
    "            # 聚合激活值\n",
    "            per_sample_means = []\n",
    "            for act in layer_acts:\n",
    "                if act.numel() > 0:\n",
    "                    # 处理不同维度的激活值\n",
    "                    if act.dim() == 3:  # [batch, seq_len, hidden]\n",
    "                        mean_act = act.mean(dim=(0, 1))  # 在batch和seq维度上平均\n",
    "                    elif act.dim() == 2:  # [batch, hidden]\n",
    "                        mean_act = act.mean(dim=0)\n",
    "                    else:\n",
    "                        mean_act = act.flatten()\n",
    "                    per_sample_means.append(mean_act)\n",
    "            \n",
    "            if not per_sample_means:\n",
    "                continue\n",
    "            \n",
    "            # 计算平均激活值\n",
    "            aggregated_act = torch.stack(per_sample_means).abs().mean(dim=0)\n",
    "            avg_activation = aggregated_act.mean().item()\n",
    "            total_neurons = aggregated_act.numel()\n",
    "            hot_neurons = (aggregated_act > avg_activation).sum().item()\n",
    "            hot_pct = (hot_neurons / total_neurons * 100) if total_neurons > 0 else 0\n",
    "            \n",
    "            layers_data.append({\n",
    "                \"layer_id\": layer_idx,\n",
    "                \"total_neurons\": total_neurons,\n",
    "                \"hot_neurons\": hot_neurons,\n",
    "                \"hot_pct\": hot_pct,\n",
    "                \"cold_neurons\": total_neurons - hot_neurons,\n",
    "                \"cold_pct\": 100 - hot_pct,\n",
    "                \"avg_activation\": avg_activation\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"dataset\": ds_name,\n",
    "            \"split\": ds_split,\n",
    "            \"num_samples\": num_samples,\n",
    "            \"average_density\": avg_density,\n",
    "            \"layers\": layers_data\n",
    "        }\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"清理钩子\"\"\"\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n",
    "        logger.info(\"已移除所有钩子\")\n",
    "\n",
    "def main():\n",
    "    # 配置\n",
    "    model_names = [\n",
    "        # \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "        # \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "        # \"Qwen/Qwen1.5-1.8B-Chat\",\n",
    "        # \"google/gemma-2-2b-it\",\n",
    "        # \"microsoft/phi-2\",\n",
    "        # \"microsoft/Phi-3.5-mini-instruct\",\n",
    "        # \"Qwen/Qwen1.5-4B-Chat\",\n",
    "        # \"THUDM/chatglm2-6b\",\n",
    "        # \"facebook/opt-6.7b\",\n",
    "        # \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        \"Qwen/Qwen2-7B-Instruct\",\n",
    "        # \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    ]\n",
    "    \n",
    "    datasets_to_use = [\n",
    "        (\"wikitext\", \"wikitext-2-raw-v1\", \"test\", \"text\"),\n",
    "        (\"gsm8k\", \"main\", \"train\", \"question\"),\n",
    "        (\"cc_news\", None, \"train\", \"text\"),\n",
    "        (\"squad\", None, \"train\", \"question\"),\n",
    "        (\"cnn_dailymail\", \"3.0.0\", \"train\", \"article\")\n",
    "    ]\n",
    "    \n",
    "    num_samples = 500\n",
    "    max_length = 128\n",
    "    \n",
    "    # 选择要测试的模型\n",
    "    selected_model = \"google/gemma-2-2b-it\"  # 修改这里来选择不同的模型\n",
    "    \n",
    "    # 创建检测器（使用单GPU模式以避免多GPU问题）\n",
    "    detector = SparsityDetector(selected_model, use_single_gpu=True)\n",
    "    \n",
    "    # 处理每个数据集\n",
    "    all_results = []\n",
    "    for dataset_info in datasets_to_use:\n",
    "        results = detector.process_dataset(dataset_info, num_samples, max_length, batch_size=1)\n",
    "        if results:\n",
    "            all_results.append(results)\n",
    "            \n",
    "            # 保存结果\n",
    "            model_folder = selected_model.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "            os.makedirs(model_folder, exist_ok=True)\n",
    "            \n",
    "            json_filename = f\"{dataset_info[0]}_activation_results.json\"\n",
    "            json_path = os.path.join(model_folder, json_filename)\n",
    "            \n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "            logger.info(f\"结果保存为: {json_path}\")\n",
    "    \n",
    "    # 清理\n",
    "    detector.cleanup()\n",
    "    logger.info(\"\\n所有数据集处理完成！\")\n",
    "    \n",
    "    # 汇总结果\n",
    "    if all_results:\n",
    "        summary_path = os.path.join(model_folder, \"summary.json\")\n",
    "        summary = {\n",
    "            \"model\": selected_model,\n",
    "            \"num_samples\": num_samples,\n",
    "            \"datasets\": [r[\"dataset\"] for r in all_results],\n",
    "            \"average_densities\": {r[\"dataset\"]: r[\"average_density\"] for r in all_results}\n",
    "        }\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=4, ensure_ascii=False)\n",
    "        logger.info(f\"汇总结果保存为: {summary_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da113f",
   "metadata": {},
   "source": [
    "## 读取生成的冷热神经元，生成热力图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c3da4",
   "metadata": {},
   "source": [
    "生成svg格式的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19af442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "热图保存为: activation_heatmap.svg\n",
      "条形图保存为: barplot_layer_0.svg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15997/3127472693.py:110: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x=layer_data_sorted.values,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "层级平均激活率图保存为: layer_average_activation.svg\n",
      "数据集平均激活率图保存为: dataset_average_activation.svg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15997/3127472693.py:149: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(x=dataset_means.values, y=dataset_means.index, palette=\"viridis\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "# 设置matplotlib使用支持SVG的后端\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# 配置\n",
    "specific_layer = 0  # 聚焦的特定层ID（可调整为30或其他）\n",
    "output_heatmap = \"activation_heatmap.svg\"  # 改为SVG格式\n",
    "output_barplot = f\"barplot_layer_{specific_layer}.svg\"  # 改为SVG格式\n",
    "\n",
    "# 设置高质量的图形参数\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "# 读取所有JSON文件\n",
    "# json_files = glob.glob(\"Qwen2.5-1.5B-Instruct/*_activation_results.json\")\n",
    "# if not json_files:\n",
    "#     print(\"未找到JSON文件！请先运行分析代码生成JSON。\")\n",
    "#     exit(1)\n",
    "\n",
    "# 配置\n",
    "# model_name =    \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# model_name =    \"meta-llama/Llama-3.2-1B-Instruct\" # Llama3.2-1B (Instruct版本)\n",
    "# model_name =    \"Qwen/Qwen1.5-1.8B-Chat\"          # Qwen1.5-1.8B (Chat版本)\n",
    "model_name =    \"google/gemma-2-2b-it\"             # Gemma2-2B (Instruct版本)\n",
    "# model_name =    \"microsoft/phi-2\"                  # Phi-2-2.7B (基础版本，无Instruct)\n",
    "# model_name =    \"microsoft/Phi-3.5-mini-instruct\"  # Phi-3.5-Mini-Instruct (3.8B Mini版本)\n",
    "# model_name =    \"Qwen/Qwen1.5-4B-Chat\"            # Qwen1.5 4B (Chat版本)\n",
    "# model_name =    \"THUDM/chatglm2-6b\"                # ChatGLM2 6B\n",
    "# model_name =    \"facebook/opt-6.7b\"                # OPT6.7B (基础版本)\n",
    "# model_name =    \"mistralai/Mistral-7B-Instruct-v0.1\" # Mistral-7B (Instruct版本)\n",
    "# model_name =    \"Qwen/Qwen2-7B-Instruct\"          # Qwen2-7B (Instruct版本)\n",
    "# model_name =    \"meta-llama/Meta-Llama-3-8B-Instruct\" # LLaMA3-8B (Instruct版本)\n",
    "\n",
    "# 根据model_name生成文件夹名称（与分析代码一致：替换/和-为_）\n",
    "model_folder = model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")  # 例如 \"meta_llama_Llama_3_2_1B_Instruct\"\n",
    "\n",
    "# 读取所有JSON文件（从模型专属文件夹中读取）\n",
    "json_files = glob.glob(os.path.join(model_folder, \"*_activation_results.json\"))\n",
    "if not json_files:\n",
    "    print(f\"未找到JSON文件在文件夹 '{model_folder}' 中！请先运行分析代码生成JSON。\")\n",
    "    exit(1)\n",
    "\n",
    "# 收集数据：{dataset: {layer_id: hot_pct}}\n",
    "data = {}\n",
    "for file in json_files:\n",
    "    with open(file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "        dataset = results[\"dataset\"]\n",
    "        data[dataset] = {}\n",
    "        for layer in results[\"layers\"]:\n",
    "            data[dataset][layer[\"layer_id\"]] = layer[\"hot_pct\"]\n",
    "\n",
    "# 构建DataFrame（行=层，列=数据集）\n",
    "layers = sorted(set(layer_id for dataset_data in data.values() for layer_id in dataset_data))\n",
    "datasets = sorted(data.keys())\n",
    "df = pd.DataFrame(index=layers, columns=datasets)\n",
    "for dataset in datasets:\n",
    "    for layer in layers:\n",
    "        value = data[dataset].get(layer, 0.0)\n",
    "        df.at[layer, dataset] = value  # 填充值\n",
    "\n",
    "# 修复：强制转换为float，填充NaN\n",
    "df = df.astype(float)\n",
    "df = df.fillna(0.0)  # 处理任何NaN\n",
    "\n",
    "# 检查DataFrame是否为空\n",
    "if df.empty:\n",
    "    print(\"DataFrame为空（无层数据），无法生成图。\")\n",
    "    exit(1)\n",
    "\n",
    "# 生成热图（类似于附件(b)：Y=层，X=数据集，颜色=热比例）\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df, \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            cmap=\"coolwarm\", \n",
    "            cbar_kws={'label': 'Hot Neuron Proportion (%)'},\n",
    "            square=False,\n",
    "            linewidths=0.5,\n",
    "            linecolor='gray')\n",
    "plt.title(\"Activation Frequency Across Layers and Datasets\", pad=20)\n",
    "plt.xlabel(\"Datasets (Tasks)\", labelpad=10)\n",
    "plt.ylabel(\"Layer ID\", labelpad=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_heatmap, format='svg', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"热图保存为: {output_heatmap}\")\n",
    "\n",
    "# 生成条形图（类似于附件(a)：聚焦特定层，Y=数据集，X=热比例）\n",
    "if specific_layer in df.index:\n",
    "    layer_data = df.loc[specific_layer]\n",
    "    # 确保layer_data是数值Series\n",
    "    layer_data = pd.to_numeric(layer_data, errors='coerce').fillna(0.0)\n",
    "    \n",
    "    # 按值排序，使条形图更清晰\n",
    "    layer_data_sorted = layer_data.sort_values(ascending=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=layer_data_sorted.values, \n",
    "                     y=layer_data_sorted.index, \n",
    "                     palette=\"coolwarm\",\n",
    "                     orient='h')\n",
    "    \n",
    "    # 在条形图上添加数值标签\n",
    "    for i, (value, name) in enumerate(zip(layer_data_sorted.values, layer_data_sorted.index)):\n",
    "        ax.text(value + 0.5, i, f'{value:.2f}%', va='center', ha='left', fontsize=9)\n",
    "    \n",
    "    plt.title(f\"Hot Neuron Proportion for Layer {specific_layer} Across Datasets\", pad=20)\n",
    "    plt.xlabel(\"Hot Neuron Proportion (%)\", labelpad=10)\n",
    "    plt.ylabel(\"Datasets (Tasks)\", labelpad=10)\n",
    "    plt.xlim(0, max(layer_data_sorted.values) * 1.2)  # 留出空间显示标签\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_barplot, format='svg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"条形图保存为: {output_barplot}\")\n",
    "else:\n",
    "    print(f\"特定层 {specific_layer} 不存在于数据中，无法生成条形图\")\n",
    "\n",
    "# 可选：生成额外的综合分析图\n",
    "# 1. 层级平均激活率分布\n",
    "output_layer_avg = \"layer_average_activation.svg\"\n",
    "layer_means = df.mean(axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(layer_means.index, layer_means.values, marker='o', linewidth=2, markersize=6)\n",
    "plt.title(\"Average Hot Neuron Proportion Across All Datasets by Layer\", pad=20)\n",
    "plt.xlabel(\"Layer ID\", labelpad=10)\n",
    "plt.ylabel(\"Average Hot Neuron Proportion (%)\", labelpad=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_layer_avg, format='svg', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"层级平均激活率图保存为: {output_layer_avg}\")\n",
    "\n",
    "# 2. 数据集平均激活率对比\n",
    "output_dataset_avg = \"dataset_average_activation.svg\"\n",
    "dataset_means = df.mean(axis=0).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=dataset_means.values, y=dataset_means.index, palette=\"viridis\")\n",
    "for i, (value, name) in enumerate(zip(dataset_means.values, dataset_means.index)):\n",
    "    ax.text(value + 0.5, i, f'{value:.2f}%', va='center', ha='left', fontsize=9)\n",
    "plt.title(\"Average Hot Neuron Proportion by Dataset\", pad=20)\n",
    "plt.xlabel(\"Average Hot Neuron Proportion (%)\", labelpad=10)\n",
    "plt.ylabel(\"Datasets\", labelpad=10)\n",
    "plt.xlim(0, max(dataset_means.values) * 1.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dataset_avg, format='svg', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"数据集平均激活率图保存为: {output_dataset_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbb0e2",
   "metadata": {},
   "source": [
    "循环生成所有模型的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "# 设置matplotlib使用支持SVG的后端\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# 设置高质量的图形参数\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "# 配置\n",
    "specific_layer = 0  # 聚焦的特定层ID（可调整为30或其他）\n",
    "\n",
    "# 所有模型列表\n",
    "model_names = [\n",
    "    \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"Qwen/Qwen1.5-1.8B-Chat\",\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    \"microsoft/phi-2\",\n",
    "    \"microsoft/Phi-3.5-mini-instruct\",\n",
    "    \"Qwen/Qwen1.5-4B-Chat\",\n",
    "    \"THUDM/chatglm2-6b\",\n",
    "    \"facebook/opt-6.7b\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    \"Qwen/Qwen2-7B-Instruct\",\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "]\n",
    "\n",
    "def process_model(model_name, specific_layer=0):\n",
    "    \"\"\"处理单个模型的数据并生成图表\"\"\"\n",
    "    print(f\"\\n=== 处理模型: {model_name} ===\")\n",
    "    \n",
    "    # 根据model_name生成文件夹名称\n",
    "    model_folder = model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "    \n",
    "    # 检查文件夹是否存在\n",
    "    if not os.path.exists(model_folder):\n",
    "        print(f\"文件夹 '{model_folder}' 不存在，跳过该模型\")\n",
    "        return False\n",
    "    \n",
    "    # 读取所有JSON文件\n",
    "    json_files = glob.glob(os.path.join(model_folder, \"*_activation_results.json\"))\n",
    "    if not json_files:\n",
    "        print(f\"未找到JSON文件在文件夹 '{model_folder}' 中！\")\n",
    "        return False\n",
    "    \n",
    "    # 收集数据：{dataset: {layer_id: hot_pct}}\n",
    "    data = {}\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r') as f:\n",
    "                results = json.load(f)\n",
    "                dataset = results[\"dataset\"]\n",
    "                data[dataset] = {}\n",
    "                for layer in results[\"layers\"]:\n",
    "                    data[dataset][layer[\"layer_id\"]] = layer[\"hot_pct\"]\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 {file} 失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not data:\n",
    "        print(f\"没有有效数据，跳过模型 {model_name}\")\n",
    "        return False\n",
    "    \n",
    "    # 构建DataFrame（行=层，列=数据集）\n",
    "    layers = sorted(set(layer_id for dataset_data in data.values() for layer_id in dataset_data))\n",
    "    datasets = sorted(data.keys())\n",
    "    df = pd.DataFrame(index=layers, columns=datasets)\n",
    "    for dataset in datasets:\n",
    "        for layer in layers:\n",
    "            value = data[dataset].get(layer, 0.0)\n",
    "            df.at[layer, dataset] = value\n",
    "    \n",
    "    # 强制转换为float，填充NaN\n",
    "    df = df.astype(float)\n",
    "    df = df.fillna(0.0)\n",
    "    \n",
    "    # 检查DataFrame是否为空\n",
    "    if df.empty:\n",
    "        print(f\"DataFrame为空（无层数据），跳过模型 {model_name}\")\n",
    "        return False\n",
    "    \n",
    "    # 生成输出文件名（保存在模型文件夹中）\n",
    "    output_heatmap = os.path.join(model_folder, \"activation_heatmap.svg\")\n",
    "    output_barplot = os.path.join(model_folder, f\"barplot_layer_{specific_layer}.svg\")\n",
    "    output_layer_avg = os.path.join(model_folder, \"layer_average_activation.svg\")\n",
    "    output_dataset_avg = os.path.join(model_folder, \"dataset_average_activation.svg\")\n",
    "    \n",
    "    # 1. 生成热图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df, \n",
    "                annot=True, \n",
    "                fmt=\".2f\", \n",
    "                cmap=\"coolwarm\", \n",
    "                cbar_kws={'label': 'Hot Neuron Proportion (%)'},\n",
    "                square=False,\n",
    "                linewidths=0.5,\n",
    "                linecolor='gray')\n",
    "    plt.title(f\"Activation Frequency Across Layers and Datasets\\n{model_name}\", pad=20)\n",
    "    plt.xlabel(\"Datasets (Tasks)\", labelpad=10)\n",
    "    plt.ylabel(\"Layer ID\", labelpad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_heatmap, format='svg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"热图保存为: {output_heatmap}\")\n",
    "    \n",
    "    # 2. 生成条形图（聚焦特定层）\n",
    "    if specific_layer in df.index:\n",
    "        layer_data = df.loc[specific_layer]\n",
    "        layer_data = pd.to_numeric(layer_data, errors='coerce').fillna(0.0)\n",
    "        layer_data_sorted = layer_data.sort_values(ascending=True)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(x=layer_data_sorted.values, \n",
    "                         y=layer_data_sorted.index, \n",
    "                         palette=\"coolwarm\",\n",
    "                         orient='h')\n",
    "        \n",
    "        for i, (value, name) in enumerate(zip(layer_data_sorted.values, layer_data_sorted.index)):\n",
    "            ax.text(value + 0.5, i, f'{value:.2f}%', va='center', ha='left', fontsize=9)\n",
    "        \n",
    "        plt.title(f\"Hot Neuron Proportion for Layer {specific_layer} Across Datasets\\n{model_name}\", pad=20)\n",
    "        plt.xlabel(\"Hot Neuron Proportion (%)\", labelpad=10)\n",
    "        plt.ylabel(\"Datasets (Tasks)\", labelpad=10)\n",
    "        plt.xlim(0, max(layer_data_sorted.values) * 1.2 if layer_data_sorted.values.any() else 100)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_barplot, format='svg', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"条形图保存为: {output_barplot}\")\n",
    "    else:\n",
    "        print(f\"特定层 {specific_layer} 不存在于数据中，跳过条形图\")\n",
    "    \n",
    "    # 3. 层级平均激活率分布\n",
    "    layer_means = df.mean(axis=1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(layer_means.index, layer_means.values, marker='o', linewidth=2, markersize=6)\n",
    "    plt.title(f\"Average Hot Neuron Proportion Across All Datasets by Layer\\n{model_name}\", pad=20)\n",
    "    plt.xlabel(\"Layer ID\", labelpad=10)\n",
    "    plt.ylabel(\"Average Hot Neuron Proportion (%)\", labelpad=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_layer_avg, format='svg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"层级平均激活率图保存为: {output_layer_avg}\")\n",
    "    \n",
    "    # 4. 数据集平均激活率对比\n",
    "    dataset_means = df.mean(axis=0).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=dataset_means.values, y=dataset_means.index, palette=\"viridis\")\n",
    "    for i, (value, name) in enumerate(zip(dataset_means.values, dataset_means.index)):\n",
    "        ax.text(value + 0.5, i, f'{value:.2f}%', va='center', ha='left', fontsize=9)\n",
    "    plt.title(f\"Average Hot Neuron Proportion by Dataset\\n{model_name}\", pad=20)\n",
    "    plt.xlabel(\"Average Hot Neuron Proportion (%)\", labelpad=10)\n",
    "    plt.ylabel(\"Datasets\", labelpad=10)\n",
    "    plt.xlim(0, max(dataset_means.values) * 1.2 if dataset_means.values.any() else 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dataset_avg, format='svg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"数据集平均激活率图保存为: {output_dataset_avg}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：循环处理所有模型\"\"\"\n",
    "    print(\"开始处理所有模型的激活数据...\")\n",
    "    \n",
    "    # 统计处理结果\n",
    "    success_count = 0\n",
    "    failed_models = []\n",
    "    \n",
    "    # 循环处理每个模型\n",
    "    for model_name in model_names:\n",
    "        try:\n",
    "            if process_model(model_name, specific_layer=specific_layer):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                failed_models.append(model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"处理模型 {model_name} 时发生错误: {e}\")\n",
    "            failed_models.append(model_name)\n",
    "    \n",
    "    # 打印汇总信息\n",
    "    print(\"\\n=== 处理完成 ===\")\n",
    "    print(f\"成功处理: {success_count} 个模型\")\n",
    "    if failed_models:\n",
    "        print(f\"失败或跳过的模型 ({len(failed_models)} 个):\")\n",
    "        for model in failed_models:\n",
    "            print(f\"  - {model}\")\n",
    "    \n",
    "    # 可选：生成跨模型对比图\n",
    "    generate_cross_model_comparison()\n",
    "\n",
    "def generate_cross_model_comparison():\n",
    "    \"\"\"生成跨模型对比图（可选）\"\"\"\n",
    "    print(\"\\n=== 生成跨模型对比图 ===\")\n",
    "    \n",
    "    # 收集所有模型的平均激活率\n",
    "    model_avg_data = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        model_folder = model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "        summary_file = os.path.join(model_folder, \"summary.json\")\n",
    "        \n",
    "        if os.path.exists(summary_file):\n",
    "            try:\n",
    "                with open(summary_file, 'r') as f:\n",
    "                    summary = json.load(f)\n",
    "                    avg_densities = summary.get(\"average_densities\", {})\n",
    "                    if avg_densities:\n",
    "                        # 计算该模型所有数据集的平均密度\n",
    "                        model_avg = sum(avg_densities.values()) / len(avg_densities) * 100\n",
    "                        model_avg_data[model_name] = model_avg\n",
    "            except Exception as e:\n",
    "                print(f\"读取 {summary_file} 失败: {e}\")\n",
    "    \n",
    "    if model_avg_data:\n",
    "        # 创建跨模型对比图\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # 排序模型（按激活率）\n",
    "        sorted_models = sorted(model_avg_data.items(), key=lambda x: x[1], reverse=True)\n",
    "        models = [m[0].split('/')[-1] for m in sorted_models]  # 简化模型名称\n",
    "        values = [m[1] for m in sorted_models]\n",
    "        \n",
    "        ax = plt.barh(models, values, color='skyblue', edgecolor='navy')\n",
    "        \n",
    "        # 添加数值标签\n",
    "        for i, v in enumerate(values):\n",
    "            plt.text(v + 0.5, i, f'{v:.1f}%', va='center', fontsize=9)\n",
    "        \n",
    "        plt.xlabel('Average Activation Density (%)', fontsize=12)\n",
    "        plt.ylabel('Models', fontsize=12)\n",
    "        plt.title('Cross-Model Activation Density Comparison', fontsize=14, pad=20)\n",
    "        plt.xlim(0, max(values) * 1.2 if values else 100)\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        output_path = \"cross_model_comparison.svg\"\n",
    "        plt.savefig(output_path, format='svg', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"跨模型对比图保存为: {output_path}\")\n",
    "    else:\n",
    "        print(\"没有足够的数据生成跨模型对比图\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 可以通过命令行参数或直接修改这里来改变specific_layer\n",
    "    specific_layer = 0  # 可以改为其他层，如15、30等\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sglang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
